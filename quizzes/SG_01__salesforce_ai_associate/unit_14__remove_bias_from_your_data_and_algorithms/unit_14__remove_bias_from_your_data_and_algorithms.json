{
  "unit_number": 14,
  "title": "Remove Bias from Your Data and Algorithms",
  "summary": "Removing bias from data and models requires proactive review and cultural awareness. This unit introduces strategies like premortems, diverse data sourcing, community feedback, and ongoing model evaluation to reduce unfairness and build inclusive AI.",
  "questions": [
    {
      "question_number": 1,
      "question": "What makes generative AI fundamentally different from predictive AI?",
      "choices": {
        "A": "It predicts future stock prices",
        "B": "It creates new, original content rather than analyzing existing trends",
        "C": "It uses less computing power",
        "D": "It never needs human supervision"
      },
      "answer": "B"
    },
    {
      "question_number": 2,
      "question": "Why is accuracy a concern in generative AI?",
      "choices": {
        "A": "AI models can\u2019t process written text",
        "B": "Users might assume the output is factually correct even when it\u2019s not",
        "C": "All AI is programmed to be inaccurate",
        "D": "It always pulls data from a live web feed"
      },
      "answer": "B"
    }
  ]
}